---
title: "Previsione del prezzo giornaliero di energia elettrica"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
---
L'obiettivo del progetto è svilupare un sistema in grado di predire i prezzi giornalieri del mercato energetico. Più nello specifico, vengono implementati diverse tipologie di algoritmi: i modelli lineari ARIMA e UCM e i modelli non lineari Knn, LSTM e GRU. Verranno analizzate, discusse e confrontate le performance di tutti i gli algoritmi sviluppati al fine di determinare il modello migliore per il fine predittivo dell'analisi.



```{r, include=F, warning=FALSE, message=FALSE}
library(forecast)
library(xts)
library(dplyr) 
library(aTSA)
library(ggplot2)
library(timeDate)
library(tidyverse)
library(KFAS)
library(tsfknn)
library(keras)
library(recipes)
library(ggpubr)
```

```{r, warning=FALSE, message=FALSE}
time_series_dataset <- read.csv("C:/Users/GiuliaChiaretti/Desktop/time series/PROGETTO/time_series_dataset.csv", sep=";")

time_series_dataset$Data = as.Date(time_series_dataset$Data)

y = xts(time_series_dataset$value, order.by = time_series_dataset$Data)

train <- y["2010-01-01/2016-12-31"]
val <- y["2017-01-01/2018-12-31"]

```

Il dataset utilizzato è costituito dalla serie storica giornaliera riferita al prezzo dell'energia elettrica. 
I dati sono relativi al periodo che va dal 1 gennaio 2010 al 31 dicembre 2018, per un totale di 3287 osservazioni. L'obiettivo è prevedere i valori giornalieri degli 11 mesi successivi: dal 1 gennaio 2019 al 30 novembre 2019.
Per l'analisi il dataset è stato diviso in training e validation set. Si è scelto di considerare come validation set gli ultimi due anni di dati a disposizione in modo da riuscire a testare e visualizzare anche le stagionalità intra-annue che caratterizzano gli andamenti dei prezzi.
La suddivisione del dataset viene rappresentata nel grafico seguente.

```{r, fig.height = 7, fig.width = 11}
time_series_dataset$split <- ifelse(time_series_dataset$Data > "2016-12-31","val", "train")

ggplot(time_series_dataset, aes(x = time_series_dataset$Data,y = time_series_dataset$value)) +
        geom_line(aes(colour = time_series_dataset$split)) +
  scale_color_manual(values=c("#003399","#FFA500")) + 
  labs( y = "Value" , x = "Date") +
  theme(legend.title = element_blank())

```
La serie non sembra presentare particolari trend crescenti o decrescenti,e anche le oscillazioni sembrano, a meno di qualche picco, essere più o meno della stessa grandezza: sembra quindi esser estaizonaria in varianza. Si vedrà, infatti, che per i modelli ARIMA la trasformazione ottimale di box-cox è con $\lambda$ molto vicino a 1. Emerge la presenza di alcuni picchi che potrebbero essere considerati outlier ma in questo caso si preferisce non trattarli come tali, quindi eliminarli o sostituirli con valori standard, in quanto potrebbero rappresentare degli eventi significativi.

Dal grafico è inoltre evidente la presenza di una stagionalità probabilmente settimanale, evidenza che aumenta riducendo l'intervallo di date visualizzate in ascissa, come visibilenel grafico seguente.
```{r, fig.height = 7, fig.width = 11}
oneyear=time_series_dataset[1:365,]
ggplot(oneyear, aes(x = oneyear$Data,y = oneyear$value))+
  geom_line(aes(), colour = "#003399")+
  labs( y = "Value" , x = "Date")

```

Vi sono infatti picchi negativi che molto probabilmente corrispondono alle giornate di sabato e domenica, cosa confermata dal seguente grafico.

```{r}
time_series_dataset$giorno <- as.factor(strftime(time_series_dataset$Data, format = '%A')) 

ggplot(time_series_dataset, aes(x=reorder(giorno,value), y=value)) + geom_boxplot() + xlab('Day') + ylab('Value') 
```

La presenza di una stagionalità settimanale, quindi, è confermata anche da una prima analisi descrittiva del livello medio di prezzo dell'energia elettrica differenziato per giorno della settimana. Dai boxplot è possibile infatti vedere che mediamente il prezzo nei weekend, ma in particolar modo di domenica, risulta essere più basso rispetto ai giorni infrasettimanali.


# ARIMA 

Al fine di identificare i processi autoregressivi e a media mobile per i modelli ARIMA, è stata seguita la procedura di Box-Jenkins.
Non avendo rilevato una particolare non stazionarietà in varianza si è effettuata una prima analisi dei correlogrammi della serie.


```{r,fig.height = 4, fig.width = 11}

par(mfrow = c(1,2))
acf(train, lag.max = 100)  
pacf(train, lag.max = 100)

```
Ci si concentra inizialmente sulla componente stagionale e, da una prima analisi sono visibili picchi ai lag stagionali (multipli di 7) sia sulla ACF che PACF quindi si conferma una non stazionarietà in media stagionale e si procede con la differenziazione stagionale. Inoltre, si può vedere che L'ACF, sia sui lag stagionali che non, sembra andare a zero anche se molto lentamente. Un andamento simile si ha per la PACF, anche se la discesa verso lo zero è in questo caso più rapida. Non si riescono ad individuare con precisione gli ordini dei processi quindi si procede inizialmente con una differenzazione stagionale di periodo 7 e la successiva stima del modello con una componente stagionale AR e MA di ordine 1.





```{r, fig.height = 7, fig.width = 11, warning=FALSE, message=FALSE}
# differenziazione stagionale
sdtrain <- diff(train,7)

ggplot(sdtrain, aes(x = Index, y = sdtrain))+
  geom_line(aes(), colour = "#003399")+
  labs( y = "Value" , x = "Date")

```

E' possibile vedere che, a seguito della differenzazione stagionale, la serie risulta stazionaria in media. Non si notano segni particolari di persistenza, infatti, la serie oscilla intorno al valore zero.
Dopo aver stimato il modello $SARIMA (0,0,0) (1,1,1)_{7}$, si analizzano i correlogrammi dei residui del modello riportati di seguito al fine di identificare e modellare la componente non stagionale del modello.

```{r}
mod1 <- Arima(sdtrain, c(0,0,0), list(order = c(1,0,1), period = 7), lambda = "auto" )
mod1
```

```{r,fig.height = 4, fig.width = 11}

par(mfrow = c(1,2))
Acf(mod1$residuals, lag.max = 36)  
Pacf(mod1$residuals, lag.max = 36)

```
Si può osservare dai correlogrammi dei residui che l'ACF tende geometricamente a zero mentre la PACF rimane sicuramente significativa nei premi 3 ritardi. Anche i lag 4, 5 e 6, tuttavia, hanno valori che risultano significativi anche se vicini alla soglia limite. Anche il lag 7 della PACF risulta ancora significativo ma per ora si preferisce ignorare la cosa in quanto potrebbero essere delle rimanenze della componente stagionale.
Quindi, si procede prima stimando i modelli con una componente autoregressiva con ordine da 2 a 6 andando ad indagare come varia il criterio di Akaike nei diversi modelli.

```{r}

mod2 <- Arima(train, c(2,0,0), list(order = c(1,1,1), period = 7), lambda = "auto" )
print (paste( "AIC del modello ARIMA (2,0,0) (1,1,1): ", round(mod2$aic,2)))

mod3 <- Arima(train, c(3,0,0), list(order = c(1,1,1), period = 7), lambda = "auto"  )
print (paste( "AIC del modello ARIMA (3,0,0) (1,1,1): ", round(mod3$aic,2)))

mod4 <- Arima(train, c(4,0,0), list(order = c(1,1,1), period = 7), lambda = "auto"  )
print (paste( "AIC del modello ARIMA (4,0,0) (1,1,1): ", round(mod4$aic,2)))

mod5 <- Arima(train, c(5,0,0), list(order = c(1,1,1), period = 7), lambda = "auto"  )
print (paste( "AIC del modello ARIMA (5,0,0) (1,1,1): ", round(mod5$aic,2)))

mod6 <- Arima(train, c(6,0,0), list(order = c(1,1,1), period = 7), lambda = "auto" )
print (paste( "AIC del modello ARIMA (6,0,0) (1,1,1): ", round(mod6$aic,2)))

```
Il modello con il valore dell'AIC minore risulta essere $SARIMA (6,0,0) (1,1,1)_{7}$.

Si procede, quindi, con l'analisi dei correlogrammi dei residui di questo modello.

```{r,fig.height = 4, fig.width = 11}

par(mfrow = c(1,2))
Acf(mod6$residuals, lag.max = 50)  
Pacf(mod6$residuals, lag.max = 50)

```
Dall'analisi di questi correlogrammi se ne deduce che gran parte della variabilità dei dati è stata colta del modello, infatti, le autocorrelazioni e le autocorrelazioni parziali risultano, a meno di qualche eccezione, non significative.

Si analizza, quindi, il modulo delle radici della componente autoregressiva.
```{r}
Mod(1/polyroot(c(1,-mod6$coef[1:6])))
```

Il quarto risulta essere molto vicino ad 1.
Potrebbe quindi essere opportuno differenziare anche non stagiornalmente la serie, effettuando quindi un'integrazione di primo ordine.

```{r}
mod6_diff <- Arima(train, c(5,1,0), list(order = c(1,1,1), period = 7), lambda = "auto" )
print (paste( "AIC del modello ARIMA (6,1,0) (1,1,1): ", round(mod6_diff$aic,2)))
```

```{r}
par(mfrow = c(1,2))
Acf(mod6_diff$residuals, lag.max = 50)
Pacf(mod6_diff$residuals, lag.max = 50)
```

Il modello con la differenzazione risulta avere un valore dell'AIC maggiore, e anche i correlogrammi dei residui hanno ancora qualche ritardo significativo. Per questi motivi se ne deduce che l'ultima differenziazione non è stata utile e si procede utilizzando il modello $SARIMA (6,0,0) (1,1,1)_{7}$ senza la differenziazione di primo ordine.


Come visto in precedenza, anche i correlogrammi di questo modello hanno ancora qualche ritardo fuori dalle bande di significatività e, proprio la presenza di queste autocorrelazioni ancora presenti, potrebbe essere sintomo della presenza di una stagionalità intra-annua; come è possibile vedere nel grafico seguente, infatti, le previsioni del modello $SARIMA (6,0,0) (1,1,1)_{7}$ sul validation set non sono accurate.


```{r, fig.height = 7, fig.width = 11}
pred_mod5 <- forecast::forecast(mod5, h=730)

ggplot() +
  autolayer(pred_mod5,series="Previsione", alpha=1) +
  autolayer(ts(val, start =length(train)+1, end = length(val)+length(train)+1), series="Validation", alpha=0.7) +
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())
```

Proprio per questo si procede valutando la possibilità di aggiungere regressori dummy e sinusoidali per migliorare l'adattabilità del modello ai dati. Solamente dopo aver trovato il modello ARIMA migliore si procederà con un'analisi sui residui di esso, per confermare che siano white noise.

Per catturare anche la componente stagionale intra-annua all'interno dei dati, sono stati costruiti dei regressori sinusoidali. In particolare, sono state considerate le prime 18 serie di seni e coseni con frequenza $\dfrac{2 \pi}{365.25}$ in modo da modellare stagionalità piuttosto liscie. 

Inoltre, per migliorare l'adattamento dei valori stimati alla serie originale sono stati introdotti dei regressori dummy rappresentanti i principali giorni di festività. E' stato assunto che i dati riguardassero il mercato elettrico italiano e, per questo motivo, sono stati considerate le seguenti festività: capodanno (31 dicembre-1 gennaio), Epifania, Pasqua, festa della liberazione, festa dei lavoratori, festa della Repubblica, ferragosto, tutti i Santi e Natale (24-26 dicembre).


```{r}
#creazione sinusoidi

freq <- outer(1:(nrow(time_series_dataset)+334), 1:18)*2*pi/365.25 # frequenza = 2*pi / periodo

cs   <- cos(freq)                   
colnames(cs) <- paste("cos", 1:18)
si   <- sin(freq)                   
colnames(si) <- paste("cos", 1:18)

sinusoidi <- as.matrix(cbind(cs,si))


# creazione dummy festività
#listHolidays("IT")

capodanno <- c(as.Date (c(NewYearsDay(2010:2019))), as.Date(paste0(2010:2019, "-12-31")))
epifania <- as.Date(c(Epiphany(2010:2019)))
pasqua <- as.Date(c(Easter(2010:2019), EasterMonday(2010:2019)))
aprile25 <- as.Date(c(ITLiberationDay(2010:2019)))
maggio1 <- as.Date(c(LaborDay(2010:2019)))
giugno2 <- as.Date(paste0(2010:2019, "-06-02"))
ferragosto <- as.Date(paste0(2010:2019, "-08-15"))
santi <- as.Date(c(ITAllSaints(2010:2019)))
natale <- c(as.Date(c(ChristmasDay(2010:2019), ChristmasEve(2010:2019))), as.Date(paste0(2010:2019, "-12-26")))

data.frame(Data=c(time_series_dataset$Data,seq(as.Date("2019-01-01"), as.Date("2019-11-30"), by="days"))) %>%
  mutate(NewYear = as.numeric(Data %in% capodanno)) %>%
  mutate(Epiphany = as.numeric(Data %in% epifania)) %>%
  mutate(Easter = as.numeric(Data %in% pasqua)) %>%
  mutate(aprile25 = as.numeric(Data %in% aprile25)) %>%
  mutate(maggio1 = as.numeric(Data %in% maggio1)) %>%
  mutate(giugno2 = as.numeric(Data %in% giugno2)) %>%
  mutate(Ferragosto = as.numeric(Data %in% ferragosto)) %>%
  mutate(santi = as.numeric(Data %in% santi)) %>%
  mutate(Christmas = as.numeric(Data %in% natale)) %>%
  select(-starts_with("Data")) %>% 
  as.matrix() -> festivita_dummy

#festivita_dummy <- as.data.frame(festivita_dummy)
```

Sono stati creati 3 differenti modelli a partire dall'$SARIMA (6,0,0) (1,1,1)_{7}$: nel primo sono stati aggiunti solamente i regressori dummy, nel secondo solamente i regressori sinusoidali e nell'ultimo sono stati aggiunti entrambi.  Le performance di questi 3 modelli sono state valutate basandosi sia sul criterio AIC, sia sulla log verosomiglianza, sia sul valore del MAPE sul training set, sia sull'analisi visiva della previsione sul validation set.

```{r}
#ARIMA (6,0,0) (1,1,1)7 con festività dummy
mod6_festivita <- Arima(train, c(6,0,0), list(order = c(1,1,1), period = 7), lambda = "auto" ,xreg=festivita_dummy[1:(length(train)),] )
summary(mod6_festivita)
print (paste("ARIMA con regressori dummy. AIC: ",mod6_festivita$aic, "   MAPE (training): 9.39   LogLik: ", mod6_festivita$loglik))
```

```{r, fig.height = 7, fig.width = 11}
pred_mod6_festivita <- forecast::forecast(mod6_festivita, h=730, 
              xreg=festivita_dummy[(length(train)+1):(length(train)+730),])

ggplot() +
  autolayer(pred_mod6_festivita,series="Previsione", alpha=0.7) +
  autolayer(ts(val, start =length(train)+1, end = length(val)+length(train)+1,frequency = frequency(val)), series="Valori veri", alpha=0.6) +
  xlab("Time") +
  ylab("Valore")
```

Il valore dell'AIC migliora rispetto al modello senza festività dummy, tuttavia le previsioni sul validation set non si adattano ancora bene ai dati. Si procede con l'inserimento dei regressori sinusoidali

```{r}
#ARIMA (6,0,0) (1,1,1)7 con regressori sinosoidali
mod6_reg <- Arima(train, c(6,0,0), list(order = c(1,1,1), period = 7), lambda = "auto",xreg=sinusoidi[1:(length(train)),] )
#summary(mod6_reg)
print (paste("ARIMA con sinusoidi. AIC: ",mod6_reg$aic, "   MAPE (training): 9.69   LogLik: ", mod6_reg$loglik))

```

```{r, fig.height = 7, fig.width = 11}
pred_mod6_reg <- forecast::forecast(mod6_reg, h=730, 
              xreg=sinusoidi[(length(train)+1):(length(train)+730),])

ggplot() +
  autolayer(pred_mod6_reg,series="Previsione", alpha=0.7) +
  autolayer(ts(val, start =length(train)+1, end = length(val)+length(train)+1,frequency = frequency(val)), series="Valori veri", alpha=0.6) +
  xlab("Time") +
  ylab("Valore")
```

Nonostante l'AIC di questo modello risulti maggiore del modello con solamente i regressori dummy, è evidente che le previsioni sul validation sono molto più accurate.

Si procede con la creazione del modello con entrambe le tipologie di regressori esterni.


```{r}
all_reg <- as.matrix(cbind(sinusoidi,festivita_dummy))

#ARIMA (6,0,0) (1,1,1)7 con regressori sinosoidali e festività
mod6_allreg <- Arima(train, c(6,0,0), list(order = c(1,1,1), period = 7), lambda = "auto",xreg=all_reg[1:(length(train)),] )
#summary(mod6_allreg)
print (paste("ARIMA con sinusoidi e festività. AIC: ",mod6_allreg$aic, "   MAPE (training): 9.27   LogLik: ", mod6_allreg$loglik))
```

```{r, fig.height = 7, fig.width = 11}
pred_mod6_allreg <- forecast::forecast(mod6_allreg, h=730, 
              xreg=all_reg[(length(train)+1):(length(train)+730),])

ggplot() +
  autolayer(pred_mod6_allreg,series="Previsione", alpha=1) +
  autolayer(ts(val, start =length(train)+1, end = length(val)+length(train)+1), series="Validation", alpha=0.7) +
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())
```

Aggiungendo al modello sua i regressori summy con le festività sia i sinusoidi l'AIC non migliora particolarmente, rimane infatti leggermente più alto del modello in cui sono state inserite solamente le festività. Tuttavia, sia sul MAPE, sia sulle previsioni sul validation si riscontra un miglioramento. Quindi si considera questo come il migliore modello ARIMA stimato.
Anche le autocorrelazioni dei residui di questo modello risultano migliorate, infatti si hanno solamente due ritardi che rimangono significativi.

```{r,fig.height = 4, fig.width = 11}

par(mfrow = c(1,2))
Acf(mod6_allreg$residuals, lag.max = 50)  
Pacf(mod6_allreg$residuals, lag.max = 50)
```

Si procede, quindi, con l'analisi dei residui. L'obiettivo è quello di verificare che siano generati da un processo white noise: a media nulla varianza costante e incorrelati con il proprio passato. 


```{r}
forecast::checkresiduals(mod6_allreg)
```
Dal plot del residui evidente che la media sia nulla, cosa che viene confermata anche dal test t effettuato di seguito per cui la media risulta essere non significativamente diversa da zero. 
Tuttavia, il test di Ljung-Box non permette di accettare l'ipotesi di assenza di autocorrelazione globale, infatti è possibile vedere che l'autocorrelazione ad alcuni ritardi rimane comunque significativa. Questo perchè trattandosi di dati reali, è difficile arrivare ad avere residui effettivamente white noise. Una cosa che invece sembra essere verificata dal grafico è la normalità dei residui: è evidente che l'istogramma empirico dei residui assomigli molto ad una normale con media nulla.

```{r}
res_mod6_allreg= mod6_allreg$residuals

media_res<-mean(res_mod6_allreg)
n<-length(res_mod6_allreg)
var_res<-(n/(n-1))*var(res_mod6_allreg) #var campionaria corretta

test_t<-(media_res/(sqrt(var_res)/sqrt(n)))

print (paste("p value test t di significatività della media dei residui: ", pt(test_t,n-1,lower.tail=F)))

```

Un'alto p value, infatti, porta ad accettare l'ipotesi nulla di media pari a zero.

La normalità dei residui viene anche confermata dal seguente grafico in cui si confrontano i valori dei residui standardizzati (quantile reale) verso la linea che individua la loro distribuzione normale (quantile terorico). Tendenzialmente, a meno delle code, si evidenza una buona aderenza delle osservazioni alla linea della distribuzione normale.

```{r}
#residui standardizzati

stand<-function(x){
  m=mean(x)
  s=(var(x)^0.5)
  z=(x-m)/s
  return(z)}
res_stand<-stand(res_mod6_allreg)

qqnorm(res_stand)
abline(0,1)
```


Per confrontare le performance predittive dei diversi modelli sviluppati è stato utilizzato come criterio il Mean Absolute Percentage Error (MAPE), dato dalla media aritmetica dei rapporti tra il valore assoluto degli errori di previsione il valore reale. Proprio per come è costruito questo indice ha il vantaggio di essere facilmente interpretabile in quanto fornisce una valutazione immediata dell'impatto dell'accuratezza previsionale, che in termini assoluti non sarebbe di così facile interpretazione.
Si specifica anche che è stato possibile utilizzare il MAPE come criterio di confronto in quanto la serie storica non presenta nessun valore prossimo allo zero. In caso di serie caratterizzate da valori molto bassi, infatti, il MAPE per costruzione assume valori molto elevati anche per i modelli che in realtà risultano essere buoni.




```{r,include=T, warning=FALSE, message=FALSE}
#MAPE mod6 con festivita e sinusoidi

#MAPE validation
temp_forecast <- forecast::forecast(mod6_allreg, h=334, xreg=all_reg[(length(train)):(length(train)+333),])
score <- c(mean(abs(temp_forecast$mean - val[1:334])/val[1:334]))

for (i in 1:(length(val) - 334)){
    temp_mod <- Arima(c(train[i:length(train)],val[1:i]), 
                      model=mod6_allreg, xreg=all_reg[i:(length(train)+i),])
    temp_forecast <- forecast::forecast(temp_mod, h=334, xreg=all_reg[(length(train)+i+1):(length(train)+i+334),])$mean
    score <- c(score, mean(abs(temp_forecast - val[(i+1):(i+334)])/val[(i+1):(i+334)]))
}

print(paste0("ARIMA validation MAPE:", mean(score)))
arima_score <- mean(score)


```

```{r}
#MAPE training
score_ARIMA_train <- mean(abs(mod6_allreg$fitted-as.numeric(train))/as.numeric(train)) 
score_ARIMA_train
```

Si calcolano quindi le previsioni future fino al 30 novembre 2019 con il modello $SARIMA (6,0,0) (1,1,1)_{7}$ a cui sono aggiunti sia i regressori dummy che sinusoidi.


```{r}
mod6_allreg_test <- Arima(y, c(6,0,0), list(order = c(1,1,1), period = 7), lambda = "auto",xreg=all_reg[1:(length(y)),] )

```

```{r, fig.height = 7, fig.width = 11}
pred_mod6_allreg_test <- forecast::forecast(mod6_allreg_test, h=334, 
              xreg=all_reg[(length(y)+1):(length(y)+334),])

autoplot(pred_mod6_allreg_test)+
  scale_color_manual(values=c("#F44611", "#003399"))

previsioni_arima <- pred_mod6_allreg_test$mean

```

















# UCM

I modelli ucm sono modelli a componenti non osservabili e permettono di combinare diverse componenti come trend, ciclo e stagionalità. In questo caso, benchè si tratti di una serie economica, non viene inserita la componente ciclica in quanto difficilmente questa influenza le previsioni one-step-ahead di un modello.


Il primo modello UCM che viene generato è dato dal local linear trend e dalla componente stagionale che in questo caso è data sia da una parte a dummy stocastiche, che modella la stagionalità settimanale, e sia da una parte trigonometrica che modella la stagionaltà intra-annua.

```{r}
# LLT + SEAS DUMMY + SEAS TRIG
ytrain <- as.numeric(train)


ucm_mod1 <- SSModel(ytrain ~ SSMtrend(2, list(NA,NA)) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                                  harmonics = 1:16),
                H = NA)

vary <- var(ytrain, na.rm = TRUE)
ucm_mod1$P1inf <- ucm_mod1$P1inf * 0
ucm_mod1$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(ucm_mod1$P1) <- vary

#si inizializzano i valori iniziali dei parametri
init <- numeric(4)
init[1] <- log(vary/10) #log varianza del livello
init[2] <- log(vary/10) #log varianza dello slope
init[3] <- log(vary/100) #log varianza dell'evoluzione della stagionalità settimanale
init[4] <- log(vary/100) #log varianza dell'evoluzione della stagionalità intra-annua
init[5] <- log(vary/10) #log varianza dell'errore di osservazione

#si definisce la funzione di aggiornamento 
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    model$Q[3, 3, 1] <- exp(pars[3])
    diag(model$Q[4:35, 4:35, 1]) <- exp(pars[4])
    model$H[1, 1, 1] <- exp(pars[5])
    model
}

fit1 <- fitSSM(ucm_mod1, inits = init, updatefn =  update_fun, control = list(maxit = 1000))
fit1$optim.out$convergence

```


```{r}
ucm_mod1_MAPEtrain <- mean(abs(fitted(fit1$model)- ytrain)/ytrain) * 100
ucm_mod1_MAPEtrain
```


```{r}
temp_data <- c(rep(NA, 334))
#tempo 0
ucm_mod <- SSModel(temp_data ~  SSMtrend(2, list(fit1$model$Q[1,1,1],fit1$model$Q[2,2,1])) +
                      SSMseasonal(7, fit1$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit1$model$Q[4, 4, 1], "trig",
                              harmonics = 1:16),
                    H = fit1$model$H)

ucm_pred <- predict(fit1$model, newdata=ucm_mod)[1:334]
valid <- as.numeric(val)[1:334]

score <- c(mean(abs(ucm_pred - valid)/valid))

for (i in 1:(length(val) - 334)){
    temp_data <- c(as.numeric(val[1:i]), rep(NA, 334))
    ucm_mod <- SSModel(temp_data ~ SSMtrend(2, list(fit1$model$Q[1,1,1],fit1$model$Q[2,2,1])) +
                      SSMseasonal(7, fit1$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit1$model$Q[4, 4, 1], "trig",
                                  harmonics = 1:16),
                    H = fit1$model$H)
    
    ucm_pred <- predict(fit1$model, newdata=ucm_mod)[(i+1):(i+334)]
    valid <- as.numeric(val)[(i+1):(i+334)]
    score <- c(score, mean(abs(ucm_pred - valid)/valid))
}

ucm_mod1_MAPEval<-mean(score)
ucm_mod1_MAPEval
```

Dal momento che nei modelli ARIMA i regressori dummy che identificano le vacanze hanno portato un miglioramento in termini predittivi, si procede aggiungendoli anche al modello a componenti non osservabili. Non vengono utilizzati come regressori invece le serie di seni e coseni in quanto la stagionalità intra-annua viene già modellata tramite le componenti non osservabili.


```{r}
# LLT + SEAS DUMMY + SEAS TRIG + REGR DUMMY
ytrain <- as.numeric(train)

festivita = as.data.frame(festivita_dummy)

ucm_mod2 <- SSModel(ytrain ~  NewYear + Epiphany + Easter + aprile25 + 
                      maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(2, list(NA,NA)) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                                  harmonics = 1:16),
                H = NA, 
                data=festivita[1:length(ytrain),])

vary <- var(ytrain, na.rm = TRUE)
ucm_mod2$P1inf <- ucm_mod2$P1inf * 0
ucm_mod2$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(ucm_mod2$P1) <- vary

# valori iniziali delle varianze
init <- numeric(5)
init[1] <- log(vary/10) 
init[2] <- log(vary/10)
init[3] <- log(vary/100)
init[4] <- log(vary/100)
init[5] <- log(vary/10)

# funzione di aggiornamento
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    model$Q[3, 3, 1] <- exp(pars[3])
    diag(model$Q[4:35, 4:35, 1]) <- exp(pars[4])
    model$H[1, 1, 1] <- exp(pars[5])
    model
}
fit2 <- fitSSM(ucm_mod2, inits = init, updatefn =  update_fun, control = list(maxit = 1000))


fit2$optim.out$convergence
```


```{r}
ucm_mod2_MAPEtrain <- mean(abs(fitted(fit2$model)- ytrain)/ytrain) * 100
ucm_mod2_MAPEtrain
```

```{r}
temp_data <- c(rep(NA, 334))

#tempo 0
ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                     maggio1 + giugno2 +Ferragosto+santi + Christmas +
                     SSMtrend(2, list(fit2$model$Q[1,1,1],fit2$model$Q[2,2,1])) +
                      SSMseasonal(7, fit2$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit2$model$Q[4, 4, 1], "trig",
                              harmonics = 1:16),
                    H = fit2$model$H,
                    data=festivita[(length(ytrain)+1):(length(ytrain)+334),])

ucm_pred <- predict(fit2$model, newdata=ucm_mod)[1:334]
valid <- as.numeric(val)[1:334]

score <- c(mean(abs(ucm_pred - valid)/valid))

for (i in 1:(length(val) - 334)){
    temp_data <- c(as.numeric(val[1:i]), rep(NA, 334))
    ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                         maggio1 + giugno2 +Ferragosto+santi + Christmas +
                          SSMtrend(2, list(fit2$model$Q[1,1,1],fit2$model$Q[2,2,1])) +
                      SSMseasonal(7, fit2$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit2$model$Q[4, 4, 1], "trig",
                                  harmonics = 1:16),
                    H = fit2$model$H,
                    data=festivita[(length(ytrain)+1):(length(ytrain)+334+i),])
    
    ucm_pred <- predict(fit2$model, newdata=ucm_mod)[(i+1):(i+334)]
    valid <- as.numeric(val)[(i+1):(i+334)]
    score <- c(score, mean(abs(ucm_pred - valid)/valid))
}

ucm_mod2_MAPEval<-mean(score)
ucm_mod2_MAPEval
```

E' possibile notare un miglioramento in termini di MAPE sia sul training che sul validation set. 

Si procede, quindi, stimando il trend non più tramite il local linear trend ma utilizzando un più semplice random walk, che potrebbe essere più utile nel fare previsioni un passo in avanti.
Dal momento che l'aggiunta dei regressori dummy delle festività ha portato miglioramenti al modello, si conservano.


```{r}
# RW + SEAS DUMMY + SEAS TRIG + REGR DUMMY
ytrain <- as.numeric(train)

ucm_mod3 <- SSModel(ytrain ~  NewYear + Epiphany + Easter + aprile25 + 
                      maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(1, NA) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                                  harmonics = 1:16),
                H = NA, 
                data=festivita[1:length(ytrain),])

vary <- var(ytrain, na.rm = TRUE)
ucm_mod3$P1inf <- ucm_mod3$P1inf * 0
ucm_mod3$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(ucm_mod3$P1) <- vary

# valori iniziali delle varianze
init <- numeric(4)
init[1] <- log(vary/10) 
init[2] <- log(vary/100)
init[3] <- log(vary/100)
init[4] <- log(vary/10)

# funzione di aggiornamento
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    diag(model$Q[3:34, 3:34, 1]) <- exp(pars[3])
    model$H[1, 1, 1] <- exp(pars[4])
    model
}

fit3 <- fitSSM(ucm_mod3, inits = init, updatefn =  update_fun, control = list(maxit = 1000))
fit3$optim.out$convergence
```


```{r}
ucm_mod3_MAPEtrain <- mean(abs(fitted(fit3$model)- ytrain)/ytrain) * 100
ucm_mod3_MAPEtrain
```

```{r}
temp_data <- c(rep(NA, 334))

#tempo 0
ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                     maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(1, fit3$model$Q[1,1,1]) +
                      SSMseasonal(7, fit3$model$Q[2,2,1], "dummy") +
                      SSMseasonal(365, fit3$model$Q[3, 3, 1], "trig",
                              harmonics = 1:16),
                    H = fit3$model$H,
                    data=festivita[1:length(temp_data),])

ucm_pred <- predict(fit3$model, newdata=ucm_mod)[1:334]
valid <- as.numeric(val)[1:334]

score <- c(mean(abs(ucm_pred - valid)/valid))

for (i in 1:(length(val) - 334)){
    temp_data <- c(as.numeric(val[1:i]), rep(NA, 334))
    ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                         maggio1 + giugno2 +Ferragosto+santi + Christmas +
                          SSMtrend(1, fit3$model$Q[1,1,1]) +
                      SSMseasonal(7, fit3$model$Q[2,2,1], "dummy") +
                      SSMseasonal(365, fit3$model$Q[3, 3, 1], "trig",
                                  harmonics = 1:16),
                    H = fit3$model$H,
                    data=festivita[1:length(temp_data),])
    
    ucm_pred <- predict(fit3$model, newdata=ucm_mod)[(i+1):(i+334)]
    valid <- as.numeric(val)[(i+1):(i+334)]
    score <- c(score, mean(abs(ucm_pred - valid)/valid))
}

ucm_mod3_MAPEval<-mean(score)
ucm_mod3_MAPEval
```

In questo caso il MAPE calcolato sul training set peggiora leggermente, tuttavia si ha un miglioramento sul valore del MAPE calcolato sul validation set.

Si esegue un ultimo cabiamento del modello inserendo un integrated random walk per modellare la componente trend.

```{r}
# IRW + SEAS DUMMY + SEAS TRIG + REGR DUMMY
ytrain <- as.numeric(train)

ucm_mod4 <- SSModel(ytrain ~  NewYear + Epiphany + Easter + aprile25 + 
                      maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(2, list(0,NA))  +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                                  harmonics = 1:16),
                H = NA, 
                data=festivita[1:length(ytrain),])

vary <- var(ytrain, na.rm = TRUE)
ucm_mod4$P1inf <- ucm_mod4$P1inf * 0
ucm_mod4$a1[1] <- mean(ytrain, na.rm = TRUE)
diag(ucm_mod4$P1) <- vary

# valori iniziali delle varianze
init <- numeric(5)
init[1] <- 0
init[2] <- log(vary/10)
init[3] <- log(vary/100)
init[4] <- log(vary/100)
init[5] <- log(vary/10) 

# funzione di aggiornamento
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    model$Q[3, 3, 1] <- exp(pars[3])
    diag(model$Q[4:35, 4:35, 1]) <- exp(pars[4])
    model$H[1, 1, 1] <- exp(pars[5])
    model
}

fit4 <- fitSSM(ucm_mod4, inits = init, updatefn =  update_fun, control = list(maxit = 1000))
fit4$optim.out$convergence
```


```{r}
ucm_mod4_MAPEtrain <- mean(abs(fitted(fit4$model)- ytrain)/ytrain) * 100
ucm_mod4_MAPEtrain
```

```{r}
temp_data <- c(rep(NA, 334))

#tempo 0
ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                     maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(2, list(0,fit4$model$Q[2,2,1])) +
                      SSMseasonal(7, fit4$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit4$model$Q[4, 4, 1], "trig",
                              harmonics = 1:16),
                    H = fit4$model$H,
                    data=festivita[1:length(temp_data),])

ucm_pred <- predict(fit4$model, newdata=ucm_mod)[1:334]
valid <- as.numeric(val)[1:334]

score <- c(mean(abs(ucm_pred - valid)/valid))

for (i in 1:(length(val) - 334)){
    temp_data <- c(as.numeric(val[1:i]), rep(NA, 334))
    ucm_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                         maggio1 + giugno2 +Ferragosto+santi + Christmas +
                          SSMtrend(2, list(0,fit4$model$Q[2,2,1])) +
                      SSMseasonal(7, fit4$model$Q[3,3,1], "dummy") +
                      SSMseasonal(365, fit4$model$Q[4, 4, 1], "trig",
                                  harmonics = 1:16),
                    H = fit4$model$H,
                    data=festivita[1:length(temp_data),])
    
    ucm_pred <- predict(fit4$model, newdata=ucm_mod)[(i+1):(i+334)]
    valid <- as.numeric(val)[(i+1):(i+334)]
    score <- c(score, mean(abs(ucm_pred - valid)/valid))
}

ucm_mod4_MAPEval<-mean(score)
ucm_mod4_MAPEval
```

Con l'utilizzo dell'integrated random walk per stimare il trend le performance peggiorano sul validation set. Per questo motivo si predilige il modello precedente in cui è stato utilizzato un random walk non integrato e se ne mostrano le performance sul validation set.

```{r, fig.height = 7, fig.width = 11}
temp_data <- c(rep(NA, 730))
temp_mod <- SSModel(temp_data ~ NewYear + Epiphany + Easter + aprile25 + 
                      maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(1, fit3$model$Q[1,1,1]) +
                      SSMseasonal(7, fit3$model$Q[2,2,1], "dummy") +
                      SSMseasonal(365, fit3$model$Q[3, 3, 1], "trig",
                              harmonics = 1:16),
                    H = fit3$model$H,
                    data=festivita[1:length(temp_data),])

temp_forecast <- predict(fit3$model, newdata=temp_mod)[1:730]

mape <- mean(abs(temp_forecast - val)/val)

ggplot() +
  autolayer(ts(val, start = length(ytrain)+1), series="Validation",size=0.4) +
  autolayer(ts(temp_forecast, start = length(ytrain)+1),
                  series="Previsione", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())
```

Di quest'ultimo modello si analizza anche il grafico dei residui delle componenti per analizzare l'evoluzione temporale delle stesse.
Questo tipo di diagnostica può essere molto utile per identficare eventuali shock nella serie.


```{r, fig.height = 7, fig.width = 11}
smo3 <- KFS(fit3$model, 
            smoothing = c("disturbance",
                          "signal")) 

dist3 <- rstandard(smo3, "state")
# si selezionano l'errore dell'evoluzione del livello, dello slope e di una stagionalità
plot(dist3[,c(1,2,15)], main= "Disturbance smoother", col="#003399")
```
  

```{r, fig.height = 7, fig.width = 11}
err_oss <- rstandard(smo3, "pearson")
plot(err_oss, main = "Errore di osservazione", ylab = "Errore di Osservazione", col= "#003399")
```


Nei grafici precedenti si evidenziano diversi cambiamenti repentini nelle componenti
non osservabili. Emerge, infatti, qualche osservazione anomala (fuori dalle bande -3/+3), ma non tale da avere necessità di creare variabili dummy per modellizzare questi shock e inserirli nel modello.

Si utilizza quindi il miglior modello UCM ottenuto per stimare i dati futuri. Il modello viene allenato novamente sull'intero dataset.

```{r}
#costruzione dataset necessario 
train_val=time_series_dataset[,-c(3,4)]
test <- data.frame(Data=seq(as.Date("2019-01-01"), as.Date("2019-11-30"), by="day"), value=NA)
data_ucm_test <- rbind(train_val,test)
y_ucm <- xts(data_ucm_test$value, order.by=data_ucm_test$Data)


```

```{r}
# RW + SEAS DUMMY + SEAS TRIG + REGR DUMMY
y_ucm <- as.numeric(y_ucm)

best_mod_ucm <- SSModel(y_ucm ~  NewYear + Epiphany + Easter + aprile25 + 
                          maggio1 + giugno2 +Ferragosto+santi + Christmas +
                      SSMtrend(1, NA) +
                      SSMseasonal(7, NA, "dummy") +
                      SSMseasonal(365, NA, "trig",
                                  harmonics = 1:16),
                H = NA, 
                data=festivita[1:length(y_ucm),])

vary <- var(y_ucm, na.rm = TRUE)
best_mod_ucm$P1inf <- best_mod_ucm$P1inf * 0
best_mod_ucm$a1[1] <- mean(y_ucm, na.rm = TRUE)
diag(best_mod_ucm$P1) <- vary

# valori iniziali delle varianze
init <- numeric(4)
init[1] <- log(vary/10) 
init[2] <- log(vary/100)
init[3] <- log(vary/100)
init[4] <- log(vary/10)

# funzione di aggiornamento
update_fun <- function(pars, model){
    model$Q[1, 1, 1] <- exp(pars[1])
    model$Q[2, 2, 1] <- exp(pars[2])
    diag(model$Q[3:34, 3:34, 1]) <- exp(pars[3])
    model$H[1, 1, 1] <- exp(pars[4])
    model
}

fit_best_mod_ucm <- fitSSM(best_mod_ucm , inits = init, updatefn =  update_fun, control = list(maxit = 1000))
fit_best_mod_ucm$optim.out$convergence
```

```{r}
smo_best_mod <- KFS(fit_best_mod_ucm$model, 
            filtering = "signal")
```


```{r}
ucm_test_value <- smo_best_mod$m[(length(y_ucm)-333):length(y_ucm)]
```







# MACHINE LEARNING

### KNN

Un primo metodo utilizzato è quello della previsione tramite kNN: vengono previsti i valori futuri basandosi sui k Nearest Neighbors, ovvero le k serie più simili all'ultimo lag temporale che precede i valori da prevedere. In questo caso è stato utilizzato come lag temporale un anno di dati. Una volta individuate le k serie più simili basandosi sulla distanza euclidea, i 334 valori futuri sono previsti tramite una media dei 334 valori che succedono le k serie identificate. Nell'effettuare questa media si è scelto di pesare maggiormente le serie più recenti tra le k identificate. 
Si è scelto di utilizzare il metodo recursivo, anzichè la metodologia MIMO-Multi Input Multi Output, in modo da avere una previsione one-step-ahead. Tramite il metodo recursivo, in ogni iterazione vengono considerati non solo tutti i dati della serie, ma anche i dati di previsione generati fino a quell'iterazione. In questo modo si aumenta la base campionaria del training set.

Per decidere k, ovvero il numero di Nearest Neighbors da considerare per poi calcolare il valor medio, una possibile soluzione è seguire un approccio euristico per cui si pone k pari alla radice quadrata della numerosità del training set. Per questo motivo si pone k pari a 50. 
```{r}
ts_train =ts(train)
ts_val = ts(val)
```

```{r}
pred_ml1 <- knn_forecasting(ts_train, h = 730, lags = 1:365,  k = 50, msas = "recursive",cf= "weighted")

# MAPE KNN 1
prediction_ml1 <- pred_ml1$prediction
ml_mod1_MAPEval <- mean(abs(prediction_ml1 - as.numeric(ts_val))/as.numeric(ts_val))
ml_mod1_MAPEval
```

Un'altro possibile approccio per definire k sarebbe stato quello di ottimizzare il parametro ma questa strategia è molto pesante a livello computazionale dati i molti valori che può assumere k e tutte le combinazioni possibili di essi.

Si opta per un'altra strategia: si utilizzano più modelli kNN con k differenti per generare le previsioni e, tramite la media di questi valori, si ottiene la previsione finale.
Si combinano 9 modelli kNN con k pari a 30, 35, 40, 45, 50, 55, 60, 65 e 70 e, grazie a questa tecnica, si può notare un lieve miglioramento in termini di MAPE.



```{r}
pred_ml2 <- knn_forecasting(ts_train, h = 730, lags = 1:365,  k = c(30,35,40,45,50,55,60,65,70), msas = "recursive",cf = "weighted")

# MAPE KNN 2
prediction_ml2 <- pred_ml2$prediction
ml_mod2_MAPEval <- mean(abs(prediction_ml2 - as.numeric(ts_val))/as.numeric(ts_val))
ml_mod2_MAPEval
```

Di seguito vengono riportate le previsioni ottenute sul validation set.

```{r, fig.height = 7, fig.width = 11}

ggplot() +
  autolayer(ts(val, start = length(ytrain)+1), series="Validation",size=0.4) +
  autolayer(pred_ml2$prediction, series="Previsione", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())
```


### RNN

Infine, sono state implementate due diverse architetture di reti neurali ricorrenti: l'LSTM (Long Short-Term Memory) e la GRU (Gated Recurrent Unit).

I dati sono stati sottoposti ad una prima fase di pre-processing in quanto questi algoritmi richiedono che i dati di input siano centrati e scalati. 
```{r}
#rimozione 29 febbraio
time_series_dataset1 <- time_series_dataset[-c(759, 2551),]

#training e validation
df_train <- time_series_dataset1[1:2555,] 
df_val <- time_series_dataset1[2556:3285,] 

df <- bind_rows(
    df_train %>% add_column(key = "training"),
    df_val %>% add_column(key = "validation")) 

rec_obj <- recipe(value ~ ., df) %>%
    step_sqrt(value) %>%
    step_center(value) %>%
    step_scale(value) %>%
    prep()

df_scaled <- bake(rec_obj, df)

# si salvano i valori per effettuare la trasformaizone inversa a seguito della previsione

center_history <- rec_obj$steps[[2]]$means["value"]
scale_history  <- rec_obj$steps[[3]]$sds["value"]

c("center" = center_history, "scale" = scale_history)
```

Inoltre, per poter essere passati in input alla rete è stato necessario trasformare i dati in array avente 3 dimensioni: la numerosità del campione, il numero di lag (timesteps) e il numero di features. In questo caso il timestep è pari a 1, così come il numero di features.

Sono stati inoltre settati i vari parametri come il numero di epoche di allenamento del modello e la batch size, ovvero il numero di campioni che verranno propagati attraverso la rete. Questo deve essere necessariamente divisibile per la numerosità di training e validation set, motivo per cui sono stati rimossi i giorni corrispondenti al 29 Febbraio.


```{r}

batch_size   <- 365     
tsteps       <- 1
epochs       <- 200

# Training 
train_lag <- df_scaled %>%
    mutate(value_lag = lag(value, 365)) %>%
    filter(!is.na(value_lag)) %>%
    filter(key == "training") 


x_train <- array(data = train_lag$value_lag, dim = c(length(train_lag$value_lag), tsteps, 1))

y_train <- array(data = train_lag$value, dim = c(length(train_lag$value), tsteps))

# Validation 
val_lag <- df_scaled%>%
    mutate(value_lag = lag(value, 365)) %>%
    filter(!is.na(value_lag)) %>%
    filter(key == "validation")
 
x_val <- array(data = val_lag$value_lag, dim = c(length(val_lag$value_lag), tsteps, 1))

y_val <- array(data = val_lag$value, dim = c(length(val_lag$value), tsteps))
```



```{r, warning=FALSE, message=FALSE,include=FALSE}

mod_lstm1 <- keras_model_sequential()

mod_lstm1 %>%
    layer_lstm(units            = 100, 
               input_shape      = c(tsteps, 1), 
               batch_size       = batch_size,
               dropout=0.3, recurrent_dropout=0.5,
               return_sequences = TRUE, 
               stateful         = TRUE) %>% 
    layer_lstm(units            = 90, 
               return_sequences = FALSE,
               dropout=0.3, recurrent_dropout=0.5,
               stateful         = TRUE) %>% 
    layer_dense(units = 1, activation = "linear") 

mod_lstm1 %>% 
    compile(loss = 'mae', optimizer = 'adam') 

mod_lstm1
```


```{r}
for (i in 1:epochs) {
    mod_lstm1 %>% fit(x= x_train, 
                  y = y_train, 
                  batch_size = batch_size,
                  epochs     = 1, 
                  verbose    = 1, 
                  shuffle    = FALSE)
    cat("Epoch: ", i)}
```
```{r, fig.height = 7, fig.width = 11}
# Previsioni
pred_lstm1_scaled<- mod_lstm1 %>% 
    predict(x_val, batch_size = batch_size) %>%
    .[,1] 

# Trasformazione inversa
pred_lstm1 <- tibble(
    Data   = val_lag$Data,
    value   = (pred_lstm1_scaled * scale_history + center_history)^2) 


ggplot() +
  autolayer(ts(df_val$value), series="Validation",size=0.4) +
  autolayer(ts(pred_lstm1$value),
                  series="Previsione", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())

```

```{r}
# MAPE validation
mape_lstm1 <- mean(abs(as.numeric(pred_lstm1$value) - as.numeric(df_val$value))/as.numeric(df_val$value))
mape_lstm1
```

I risultati ottenuti sul alidation set sono soddisfacenti, ma migliorabili.
Si procede, quindi, con lo sviluppo della seconda rete ricorrente caratterizata da un'architettura GRU.

```{r}

mod_gru1 <- keras_model_sequential()

mod_gru1 %>%
    layer_gru(units  = 90, 
               input_shape = c(tsteps, 1), 
               batch_size  = batch_size,
              dropout=0.3, recurrent_dropout=0.5) %>% 
    layer_dense(units = 1, activation = "linear") 

mod_gru1 %>% 
    compile(loss = 'mae', optimizer = 'adam') #adam

mod_gru1
```

```{r}
for (i in 1:epochs) {
    mod_gru1 %>% fit(x  = x_train, 
                  y    = y_train, 
                  batch_size = batch_size,
                  epochs     = 1, 
                  verbose    = 1, 
                  shuffle    = FALSE)

    cat("Epoch: ", i)
    
}
```

```{r, fig.height = 7, fig.width = 11}
# Previsioni
pred_gru1_scaled <- mod_gru1 %>% 
    predict(x_val, batch_size = batch_size) %>%
    .[,1] 

# Trasformazione inversa
pred_gru1 <- tibble(
    Data   = val_lag$Data,
    value   = (pred_gru1_scaled * scale_history + center_history)^2) 


ggplot() +
  autolayer(ts(df_val$value), series="Validation",size=0.4) +
  autolayer(ts(pred_gru1$value),
                  series="Previsione", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank())

```


```{r}
# MAPE validation
mape_gru1 <- mean(abs(as.numeric(pred_gru1$value) - as.numeric(df_val$value))/as.numeric(df_val$value))
mape_gru1
```

Il mape è nettamente migliore sia rispetto alla rete LSTM sia rispetto alla previsione tramite KNN. 
Per questo motivo si considera quest'ultimo come modello migliore tra i modelli non lineari testati e si procede ristimando lo stesso modello utilizzando la totalità della serie. In questo caso nei regressori non entrerà l'anno 2018, che invece verrà usato per prevedere i 334 valori futuri.

```{r}
#rimozione 29 febbraio
time_series_dataset1 <- time_series_dataset[-c(759, 2551),]

#training 
df_train_all <- time_series_dataset1

rec_obj2 <- recipe(value ~ ., df_train_all) %>%
    step_sqrt(value) %>%
    step_center(value) %>%
    step_scale(value) %>%
    prep()

df_train_all_scaled<- bake(rec_obj2, df_train_all)

# si salvano i valori per effettuare la trasformaizone inversa a seguito della previsione

center_history <- rec_obj2$steps[[2]]$means["value"]
scale_history  <- rec_obj2$steps[[3]]$sds["value"]

train_all_lag <- df_train_all_scaled %>%
    mutate(value_lag = lag(value, 365)) %>%
    filter(!is.na(value_lag)) 


x_train_all <- array(data = train_all_lag$value_lag, dim = c(length(train_all_lag$value_lag), tsteps, 1))


y_train_all <- array(data = train_all_lag$value, dim = c(length(train_all_lag$value), tsteps))
```

```{r}

mod_gru1 <- keras_model_sequential()

mod_gru1 %>%
    layer_gru(units  = 90, 
               input_shape = c(tsteps, 1), 
               batch_size  = batch_size,
              dropout=0.3, recurrent_dropout=0.5) %>% 
    layer_dense(units = 1) 

mod_gru1 %>% 
    compile(loss = 'mae', optimizer = 'adam') #adam

mod_gru1
```

```{r}
for (i in 1:epochs) {
    mod_gru1 %>% fit(x  = x_train_all, 
                  y    = y_train_all, 
                  batch_size = batch_size,
                  epochs     = 1, 
                  verbose    = 1, 
                  shuffle    = FALSE)

    cat("Epoch: ", i)
    
}
```

```{r}

x_2018 <- df_train_all_scaled[2921:3285,]
x_2018_arr <- array(data = x_2018$value, dim = c(length(x_2018$value), tsteps, 1))
```



```{r, fig.height = 7, fig.width = 11}
# Previsioni
final_pred_gru1_scaled <- mod_gru1 %>% 
    predict(x_2018_arr, batch_size = batch_size) %>%
    .[,1] 

# Trasformazione inversa
final_pred_gru1 <- tibble(
    Data   = seq(from = as.Date('2019-01-01'), to=as.Date('2019-12-31'), by = 1),
    value   = (final_pred_gru1_scaled * scale_history + center_history)^2) 

final_pred_gru1 <- final_pred_gru1[1:334,]
```



# Confronti finali

Si riportano i grafici contenenti le previsioni dei 3 modelli risultati migliori tra le categorie ARIMA, UCM e Machine Learning.
Questi sono rispettivamente:
- il modello $SARIMA (6,0,0) (1,1,1)_{7}$ con l'aggiunta di regressory dummy e sinusoidali;
- il modello UCM con il random walk per modellare la componente trend e stagionalità sia a dummy stocastiche (settimanale) che a sinusoidi stocastici (intra-annua);
- la rete neurale ricorrente GRU. 



```{r}
g1 <- ggplot() +
  autolayer(ts(y), series="Serie originale",size=0.4) +
  autolayer(ts(previsioni_arima, start = length(y)+1) , series="Previsione ARIMA", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank(),legend.position = "top")

g2 <- ggplot() +
  autolayer(ts(y), series="Serie originale",size=0.4) +
  autolayer(ts(ucm_test_value, start = length(y)+1) , series="Previsione UCM", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank(),legend.position = "top")

g3 <- ggplot() +
  autolayer(ts(y), series="Serie originale",size=0.4) +
  autolayer(ts(final_pred_gru1$value, start = length(y)+1) , series="Previsione ML", size=0.4)+
  xlab("Time") +
  ylab("Value")+
  scale_color_manual(values=c("#F44611", "#003399"))+
  theme(legend.title = element_blank(), legend.position = "top")
```

```{r, fig.height = 7, fig.width = 11}

ggarrange(g1, g2, g3 ,
          ncol = 2, nrow = 2)
```

Si riportano anche le performance in termini di mape sul validation set dei suddetti modelli.
```{r}
print (paste("MAPE ARIMA", as.character(round(arima_score,3))))
print (paste("MAPE UCM", as.character(round(ucm_mod3_MAPEval,3))))
print (paste("MAPE ML", as.character(round(mape_gru1,3))))
```

In conclusione viene generato un file csv con le previsioni fornite dai suddetti modelli:


```{r}

previsioni_all<- final_pred_gru1 %>% 
  mutate(ARIMA = as.numeric(previsioni_arima) ) %>%
  mutate(UCM = ucm_test_value) %>%
  select(Data, ARIMA, UCM, ML = value)
```


```{r}
write.csv(previsioni_all, file="SDMTSA_800928_1.csv", row.names = FALSE)
```




















